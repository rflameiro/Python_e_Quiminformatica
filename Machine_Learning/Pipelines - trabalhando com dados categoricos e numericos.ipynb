{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52e2aac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# *Pipelines* - trabalhando com dados categóricos e numéricos\n",
    "\n",
    "Um *pipeline* é uma forma de organizar em um único objeto uma sequência de operações a serem realizadas sobre nossos dados. A saída de uma operação torna-se a entrada da próxima e assim por diante, até que os dados completamente processados saiam no final. Eles deixam o código mais conciso, legível e, geralmente, mais rápido. Também fica fácil adicionar ou remover etapas conforme for necessário. \n",
    "\n",
    "`Pipeline` também é o nome do objeto da biblioteca `scikit-learn` usado para aplicar essas sequências de transformações a um conjunto de dados. \n",
    "\n",
    "Vamos mostrar como usar os *pipelines* e apresentar um exemplo ao final, usando o conjunto de dados Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e303e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_selection import SelectKBest, VarianceThreshold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, KFold, train_test_split \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, MinMaxScaler, Normalizer, MaxAbsScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d56c2",
   "metadata": {},
   "source": [
    "## Criando um *Pipeline*\n",
    "\n",
    "Um `Pipeline` é construído usando uma lista de tuplas (método, estimador), na qual \"método\" é uma *string* contendo o nome que você deseja dar à etapa e \"estimador\" é um objeto que implementa os métodos `fit` e `transform`.\n",
    "\n",
    "Suponha que você queira fazer as seguintes manipulações nos seus dados:\n",
    "- Preencher valores faltantes com a mediana dos valores da coluna\n",
    "- Remover variáveis com variância menor que 0.1\n",
    "- Padronizar os dados (subtrair a média e dividir pelo desvio padrão)\n",
    "\n",
    "O *Pipeline* abaixo pode ser usado para realizar essas etapas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbf4f9f-17a9-4ecf-853d-0397e8b7c02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;selector&#x27;, VarianceThreshold(threshold=0.1)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;selector&#x27;, VarianceThreshold(threshold=0.1)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('selector', VarianceThreshold(threshold=0.1)),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # Preenche linhas sem valores com a mediana\n",
    "    (\"selector\", VarianceThreshold(0.1)),  # Remove descritores variância < 0.1\n",
    "    (\"scaler\", StandardScaler()),  # Padronização\n",
    "])\n",
    "\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4944abff-4ccd-4b51-b413-c58e69034c68",
   "metadata": {},
   "source": [
    "Alternativamente, podemos criar o mesmo *Pipeline* a partir de uma lista de tuplas (método, estimador):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abde2645-583e-4731-b947-af940c50b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;selector&#x27;, VarianceThreshold(threshold=0.1)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                (&#x27;selector&#x27;, VarianceThreshold(threshold=0.1)),\n",
       "                (&#x27;scaler&#x27;, StandardScaler())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold(threshold=0.1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('imputer', SimpleImputer(strategy='median')),\n",
       "                ('selector', VarianceThreshold(threshold=0.1)),\n",
       "                ('scaler', StandardScaler())])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "etapas = []\n",
    "\n",
    "etapas.append((\"imputer\", SimpleImputer(strategy=\"median\")))\n",
    "etapas.append((\"selector\", VarianceThreshold(0.1)))\n",
    "etapas.append((\"scaler\", StandardScaler()))\n",
    "\n",
    "pipeline = Pipeline(etapas)\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636c2a9d-3156-42d9-952e-1be75568dcfd",
   "metadata": {},
   "source": [
    "## *Pipelines* para diferentes tipos de variáveis\n",
    "\n",
    "Diferentes tipos de variáveis requerem manipulações diferentes. Por exemplo, não faz sentido calcular médias para variáveis categóricas. Assim, é uma prática comum identificar suas variáveis de acordo com o tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478417ad-0d12-4c95-a7b2-68aaa1a1cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar DataFrame\n",
    "dados = {\n",
    "    'Idade': [25, 30, 35, 40, 45, 50, 55, 60, 65, 70],\n",
    "    'Altura': [1.70, 1.75, 1.80, np.NaN, 1.90, 1.80, 1.75, 1.68, 1.72, 1.78],\n",
    "    'Gênero': ['M', 'F', 'M', 'I', 'M', 'M', np.NaN, 'I', 'F', 'M'],\n",
    "    'Casado': ['Sim', 'Sim', 'Não', 'Sim', 'Não', 'Sim', 'Não', 'Sim', 'Não', 'Sim'],\n",
    "    'Ensino_superior': ['Sim', 'Sim', np.NaN, 'Sim', 'Não', 'Sim', 'Sim', 'Sim', 'Não', 'Não']\n",
    "}\n",
    "\n",
    "X = pd.DataFrame(dados)\n",
    "y = [50000, 60000, 30000, 50000, 40000, 100000, 11000, 20000, 13000, 14000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313499b8-39bf-414b-b493-42d18ffb3d84",
   "metadata": {},
   "source": [
    "Caso suas variáveis já estejam com os `dtypes` corretos, é fácil separar as numéricas das categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af859742-253a-4f27-9c8a-af452cec8a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Idade                int64\n",
      "Altura             float64\n",
      "Gênero              object\n",
      "Casado              object\n",
      "Ensino_superior     object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e34525a6-d172-4130-9b02-022b991d508d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = [col for col in X.columns if X[col].dtype in ['int64',\n",
    "                                                                  'float64']]\n",
    "categorical_columns = [col for col in X.columns if X[col].dtype==\"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef727e1f-e975-4198-b625-88cddbdf2cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Também é possível listar manualmente as variáveis desejadas\n",
    "numerical_features = [\"Idade\", \"Altura\"]\n",
    "categorical_features = [\"Gênero\", \"Casado\", \"Ensino_superior\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a195fd65-cf9c-4593-a010-b727ae932c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Pipeline para variáveis numéricas\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),  # Preenche linhas sem valores com a mediana\n",
    "    (\"selector\", VarianceThreshold()),  # Remove descritores com baixa variância\n",
    "    (\"scaler\", StandardScaler()),  # Padronização\n",
    "    (\"feature_selection\", SelectKBest(k=20)),  # Seleção de variáveis\n",
    "    (\"PCA\", PCA(n_components=2))  # Projeção para redução de dimensionalidade\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03a55499-79fb-4d47-8666-e10d56ab1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Pipeline para variáveis categóricas\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"encoder\", LabelEncoder())  # Transforma variável categórica no formato texto em numérica\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8834cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de Pipeline para variáveis categóricas\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # Preenche linhas sem valores com a entrada mais comum\n",
    "    (\"OHE\", OneHotEncoder(drop=\"first\"))  # transforma categorias em vetores numéricos\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22e925-f522-447e-890b-e29697cf195a",
   "metadata": {},
   "source": [
    "**Importante:** conheça bem todas as funções que pretende usar no seu *pipeline* para não ter surpresas. Por exemplo, o `SimpleImputer()` exige a identificação dos valores que representam valores faltantes (vamos usar `missing_values=np.NaN` no exemplo abaixo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7313c74",
   "metadata": {},
   "source": [
    "## ColumnTransformer\n",
    "\n",
    "O `ColumnTransformer` nos permite juntar *Pipelines* que operam em diferentes variáveis dos nossos conjuntos de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b1ed3cd-ed21-4cf7-a894-3f322c83abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "numerical_features = [\"Idade\", \"Altura\"]\n",
    "categorical_features = [\"Gênero\", \"Casado\", \"Ensino_superior\"]\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\", missing_values=np.NaN)),\n",
    "    (\"selector\", VarianceThreshold()),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\", missing_values=np.NaN)),\n",
    "    (\"OHE\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# Combinando os pipelines\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"numerical\", numerical_pipeline, numerical_features),\n",
    "    (\"categorical\", categorical_pipeline, categorical_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9865d35-5517-4c02-bafb-3f50205057db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.566699</td>\n",
       "      <td>-1.064742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.218544</td>\n",
       "      <td>-0.219709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.870388</td>\n",
       "      <td>0.625325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.522233</td>\n",
       "      <td>-0.219709</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.174078</td>\n",
       "      <td>2.315392</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.174078</td>\n",
       "      <td>0.625325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.522233</td>\n",
       "      <td>-0.219709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.870388</td>\n",
       "      <td>-1.402756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.218544</td>\n",
       "      <td>-0.726729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.566699</td>\n",
       "      <td>0.287311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1    2    3    4    5\n",
       "0 -1.566699 -1.064742  0.0  1.0  1.0  1.0\n",
       "1 -1.218544 -0.219709  0.0  0.0  1.0  1.0\n",
       "2 -0.870388  0.625325  0.0  1.0  0.0  1.0\n",
       "3 -0.522233 -0.219709  1.0  0.0  1.0  1.0\n",
       "4 -0.174078  2.315392  0.0  1.0  0.0  0.0\n",
       "5  0.174078  0.625325  0.0  1.0  1.0  1.0\n",
       "6  0.522233 -0.219709  0.0  1.0  0.0  1.0\n",
       "7  0.870388 -1.402756  1.0  0.0  1.0  1.0\n",
       "8  1.218544 -0.726729  0.0  0.0  0.0  0.0\n",
       "9  1.566699  0.287311  0.0  1.0  1.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos aplicar o pipeline ao conjunto de dados\n",
    "pd.DataFrame(preprocessor.fit_transform(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56daafc8-4b81-48c1-b8a8-c7773baa0e7e",
   "metadata": {},
   "source": [
    "Veja que a idade e a altura foram padronizadas (duas primeiras colunas), a variável Gênero foi convertida a duas colunas numéricas pelo OHE, e as outras colunas foram convertidas a valores binários. Nenhum valor está faltando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76592329-8a27-42bd-8b91-a30af5ea84f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Mostrando *Pipelines*\n",
    "\n",
    "Para mostrar um *Pipeline* em um Jupyter Notebook no formato de texto, basta usar a função `print()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "834b3a26-1d68-4780-b699-714d599a672c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ColumnTransformer(transformers=[('numerical',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='median')),\n",
      "                                                 ('selector',\n",
      "                                                  VarianceThreshold()),\n",
      "                                                 ('scaler', StandardScaler())]),\n",
      "                                 ['Idade', 'Altura']),\n",
      "                                ('categorical',\n",
      "                                 Pipeline(steps=[('imputer',\n",
      "                                                  SimpleImputer(strategy='most_frequent')),\n",
      "                                                 ('OHE',\n",
      "                                                  OneHotEncoder(drop='first'))]),\n",
      "                                 ['Gênero', 'Casado', 'Ensino_superior'])])\n"
     ]
    }
   ],
   "source": [
    "print(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8ae2a7-bc46-4d0b-8241-03a5a0863f5b",
   "metadata": {},
   "source": [
    "Se apenas chamar o *pipeline* na célula, ele pode ser apresentado como texto ou diagrama. No meu Notebook, ele já fica no formato diagrama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19f4e3f5-00ef-4e1e-9fa4-6c4e84c2681b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;selector&#x27;,\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Idade&#x27;, &#x27;Altura&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OHE&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;selector&#x27;,\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Idade&#x27;, &#x27;Altura&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OHE&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Idade&#x27;, &#x27;Altura&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('numerical',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('selector',\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['Idade', 'Altura']),\n",
       "                                ('categorical',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('OHE',\n",
       "                                                  OneHotEncoder(drop='first'))]),\n",
       "                                 ['Gênero', 'Casado', 'Ensino_superior'])])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d26d0-7bcf-4c07-b4bc-0fcb4dd48a29",
   "metadata": {},
   "source": [
    "Caso no seu apareça como texto, ainda é possível mostrá-lo no formato diagrama, usando `set_config`. Veja mais [aqui](https://scikit-learn.org/dev/auto_examples/miscellaneous/plot_pipeline_display.html#sphx-glr-auto-examples-miscellaneous-plot-pipeline-display-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4f2055d-a249-4556-a303-83793572a86c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;selector&#x27;,\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Idade&#x27;, &#x27;Altura&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OHE&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;])])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;numerical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;selector&#x27;,\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;Idade&#x27;, &#x27;Altura&#x27;]),\n",
       "                                (&#x27;categorical&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n",
       "                                                 (&#x27;OHE&#x27;,\n",
       "                                                  OneHotEncoder(drop=&#x27;first&#x27;))]),\n",
       "                                 [&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numerical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Idade&#x27;, &#x27;Altura&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" ><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-21\" type=\"checkbox\" ><label for=\"sk-estimator-id-21\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">categorical</label><div class=\"sk-toggleable__content\"><pre>[&#x27;Gênero&#x27;, &#x27;Casado&#x27;, &#x27;Ensino_superior&#x27;]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('numerical',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('selector',\n",
       "                                                  VarianceThreshold()),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['Idade', 'Altura']),\n",
       "                                ('categorical',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('OHE',\n",
       "                                                  OneHotEncoder(drop='first'))]),\n",
       "                                 ['Gênero', 'Casado', 'Ensino_superior'])])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import set_config\n",
    "\n",
    "set_config(display=\"diagram\")\n",
    "\n",
    "preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07b77ac-637a-4e73-83d3-3133053cd0d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Adicionando um modelo ao *Pipeline*\n",
    "\n",
    "Além de processar dados, é possível também incluir um estimador (por exemplo, um modelo de classificação/regressão) como etapa **final** do `Pipeline`. As etapas intermediárias devem ser necessariamente transformações dos dados. Em termos de métodos do `scikit-learn`, dizemos que as etapas intermediárias devem implementar os métodos `fit()` e `transform()`, enquanto o estimador final só precisa implementar o `fit()`.\n",
    "\n",
    "Veja abaixo um exemplo em que fazemos uma seleção de variáveis com variância maior que 0.2, seguida de padronização e criação de um modelo de classificação usando k-NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2eda6567-8cb7-44ac-a00c-0aecfda1c44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic classification data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d89fcb67-c1be-41a5-9eab-34e56476e5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "    (\"selector\", VarianceThreshold()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eded604f-b739-4cab-b704-ebb871304f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;selector&#x27;, VarianceThreshold()),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-25\" type=\"checkbox\" ><label for=\"sk-estimator-id-25\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;selector&#x27;, VarianceThreshold()),\n",
       "                (&#x27;classifier&#x27;, KNeighborsClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-26\" type=\"checkbox\" ><label for=\"sk-estimator-id-26\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VarianceThreshold</label><div class=\"sk-toggleable__content\"><pre>VarianceThreshold()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" ><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('selector', VarianceThreshold()),\n",
       "                ('classifier', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para treinar o modelo:\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4ceac5-1d3e-45ca-b40b-e0e7df2604d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predições: [0 1 0 1 0 1 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 1\n",
      " 1 0 1 0 1 0 0 0 0 1 1 1 1 0 1 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0\n",
      " 1 0 0 1 0 1 0 0 1 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 0 1 0 1 0 0 1 0 1 0 1 1\n",
      " 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1 1 1 0 1 1 0 1 1 0 0 0 0 0 1 1 0 0 0 1 1 1 0\n",
      " 0 0 1 0 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1]\n",
      "Acurácia no conjunto de teste:  0.8\n"
     ]
    }
   ],
   "source": [
    "# E usamos o pipeline para fazer previsões para os dados de teste\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Predições:\", y_pred)\n",
    "\n",
    "# Calcular erro quadrado médio para a predição\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Acurácia no conjunto de teste: \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e9308-37bb-451a-8ed4-626a2a51a96b",
   "metadata": {},
   "source": [
    "## Uso de *pipelines* com validação cruzada\n",
    "\n",
    "Sabemos que não é recomendável aplicar transformações (por exemplo, padronizar os dados) a um conjunto de dados completo, antes de separar em conjunto de treinamento e teste, devido ao problema denominado *data leakage*. Usando `Pipeline` podemos reunir várias etapas de manipulação dos dados em um único transformador, permitindo, por exemplo, um tratamento individual para cada *fold* em uma validação cruzada, evitando assim o *data leakage*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b99fb5b-5226-4b18-84bd-20c38caa24ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.82934132 0.84384384 0.81681682]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "# Criar pipeline\n",
    "model = Pipeline([\n",
    "    (\"selector\", VarianceThreshold()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Avaliar modelo usando validação cruzada\n",
    "# As etapas serão executadas individualmente em cada fold\n",
    "kfold = KFold(n_splits=3)\n",
    "results = cross_val_score(model, X, y, cv=kfold, scoring=\"accuracy\")\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ea6267-b25d-4272-a6b8-ca4819025188",
   "metadata": {},
   "source": [
    "## Usando um *Pipeline* para ajustar hiperparâmetros\n",
    "\n",
    "Podemos incluir diferentes métodos e/ou hiperparâmetros de métodos a um dicionário, usá-lo em um *grid search* e adicionar os valores que fornecerem os melhores resultados a um *Pipeline*. Note que no caso de hiperparâmetros, os nomes dos métodos devem corresponder aos nomes definidos pelo `scikit-learn`.\n",
    "\n",
    "Abaixo, vamos criar um *pipeline* com as etapas:\n",
    "- Padronização\n",
    "- Remoção de variáveis com baixa variância\n",
    "- Modelo classificador k-NN\n",
    "\n",
    "E vamos tentar encontrar a melhor combinação para:\n",
    "- Método de padronização (etapa 1)\n",
    "- *Threshold* para a variância (etapa 2)\n",
    "- Hiperparâmetros n_neighbors, p e leaf_size do KNeighborsClassifier (etapa 3)\n",
    "\n",
    "Veja que os parâmetros dos estimadores no *pipeline* podem ser acessados usando a sintaxe `estimator__parameter`\n",
    "\n",
    "[Fonte](https://machinelearningmastery.com/modeling-pipeline-optimization-with-scikit-learn/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "accce790-d96d-43f3-bf9e-e0df00d6aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score conjunto de treinamento: 0.88625\n",
      "Score conjunto de teste: 0.845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('selector', VarianceThreshold()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# Dicionário com o grid de hiperparâmetros que vamos explorar\n",
    "parameters = {\n",
    "    'scaler': [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],\n",
    "    'selector__threshold': [0, 0.001, 0.01],\n",
    "    'classifier__n_neighbors': [1, 5, 10],\n",
    "    'classifier__p': [1, 2],\n",
    "    'classifier__leaf_size': [1, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=parameters, cv=2).fit(X_train, y_train)\n",
    " \n",
    "print('Score conjunto de treinamento: ' + str(grid_search.score(X_train, y_train)))\n",
    "print('Score conjunto de teste: ' + str(grid_search.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02155d82-1dc6-408b-8bc7-53ea444187c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__leaf_size': 1, 'classifier__n_neighbors': 10, 'classifier__p': 1, 'scaler': Normalizer(), 'selector__threshold': 0}\n"
     ]
    }
   ],
   "source": [
    "# Acessar os melhores hiperparâmetros\n",
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4f67c964-e7c1-4602-91fa-2bcfa08bb4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', Normalizer()),\n",
      "                ('selector', VarianceThreshold(threshold=0)),\n",
      "                ('classifier',\n",
      "                 KNeighborsClassifier(leaf_size=1, n_neighbors=10, p=1))])\n"
     ]
    }
   ],
   "source": [
    "# Salvar os melhores hiperparâmetros na variável best_pipe\n",
    "best_pipe = grid_search.best_estimator_\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1763b521-1817-49cc-97df-b486db055ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acessando o valor de p do k-NN pipeline final\n",
    "best_pipe.get_params()['classifier__p']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800087f0-59a8-4ecd-a715-86627e04d102",
   "metadata": {},
   "source": [
    "Etapas não finais podem ser ignoradas usando \"passthrough\". \n",
    "\n",
    "No exemplo abaixo, mostramos como explorar o efeito redução de dimensionalidade no preprocessamento dos dados, testando as seguintes situações: nenhuma redução de dimensionalidade, PCA com 5 PCs e PCA com 10 PCs. Também testamos dois classificadores distintos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "206b961a-6778-4762-bee6-046135c17dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('reduce_dim', PCA()),\n",
    "    ('classifier', KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "param_grid = dict(reduce_dim=[\"passthrough\", PCA(5), PCA(10)],\n",
    "                  classifier=[KNeighborsClassifier(), LogisticRegression()])\n",
    "\n",
    "grid_search = GridSearchCV(pipe, param_grid=param_grid, cv=2).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b0c154f-f325-4f3e-bff7-eb6420777b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier': LogisticRegression(), 'reduce_dim': PCA(n_components=5)}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d1c1e3-d53a-42f9-ac7e-0422647a32f4",
   "metadata": {},
   "source": [
    "## Criando um transformador personalizado\n",
    "\n",
    "Em alguns casos, podemos querer usar uma etapa em um *Pipeline* para a qual não existe função implementada. Podemos criar nossas próprias classes, lembrando que ela necessariamente deverá implementar os métodos `fit()` e `transform()`.\n",
    "\n",
    "Veja abaixo uma função para remover variáveis correlacionadas entre si, que usei no Notebook [Seleção de variáveis e Redução de dimensionalidade](https://github.com/rflameiro/Python_e_Quiminformatica/blob/main/Machine_Learning/Sele%C3%A7%C3%A3o%20de%20vari%C3%A1veis%20e%20Redu%C3%A7%C3%A3o%20de%20dimensionalidade.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f604557a-cf2f-4148-8e2d-bb4daa67a614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8f73cf8-e8df-4f90-a40b-97196b46a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para remover variáveis correlacionadas entre si\n",
    "# Adaptado de https://github.com/fraunhoferportugal/tsfel/issues/91\n",
    "class CorrelationThreshold(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, threshold = 0.9):\n",
    "        self.threshold = threshold\n",
    "        self.to_drop = None\n",
    "        self.to_keep = None\n",
    "\n",
    "    def fit(self, X, y=None): \n",
    "        corr_matrix = X.corr(method='pearson').abs()\n",
    "        upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "        self.to_drop = [column for column in upper.columns if any(upper[column] > self.threshold)]\n",
    "        # self.to_keep = list(set(X.columns) - set(self.to_drop))\n",
    "        # The method above does not preserve the order of the columns\n",
    "        self.to_keep = [value for value in X.columns if value not in self.to_drop]\n",
    "        return self\n",
    "        \n",
    "    def transform(self, X, y = None):\n",
    "        X_selected = X[self.to_keep]\n",
    "        return X_selected\n",
    "    \n",
    "    def get_support(self):\n",
    "        return self.to_keep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8f96d-1016-426d-af20-8a3ab24de01f",
   "metadata": {},
   "source": [
    "## make_pipeline\n",
    "\n",
    "A função utilitária `make_pipeline()` facilita a construção de *pipelines*; ela toma como entrada um número qualquer de estimadores e retorna um *pipeline*, preenchendo os nomes automaticamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e090f4e2-f430-4e92-b28e-bbf8286c8237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "pipe = make_pipeline(Binarizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e67921fd-8c0e-4d97-b952-bd3f10840972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('binarizer', Binarizer()), ('multinomialnb', MultinomialNB())])\n"
     ]
    }
   ],
   "source": [
    "print(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a018a730-844c-4703-bcf6-8fba4be4ae40",
   "metadata": {},
   "source": [
    "## FeatureUnion\n",
    "\n",
    "Parecido com o *Pipeline* mas, em vez de realizar as operações sequencialmente, as realiza em paralelo e concatena os resultados. Por exemplo, o objeto abaixo realizará duas reduções de dimensionalidade, uma com PCA e outra com SVD, e todas as colunas resultantes (uma da PCA e duas da SVD) serão incluídas no *DataFrame* resultante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c84be0c8-6ceb-4cb9-a249-66c252816e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.80155683,  2.89772015, -1.07557265],\n",
       "       [-0.44937328,  5.63365372, -0.97470578],\n",
       "       [ 0.41367381,  3.73706775, -0.04782552],\n",
       "       [-1.76585736,  5.10116037,  1.72246899]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "union = FeatureUnion([(\"pca\", PCA(n_components=1)),\n",
    "                      (\"svd\", TruncatedSVD(n_components=2))])\n",
    "\n",
    "X = [[0., 1., 3], [2., 2., 5], [1., 2., 3], [2., 4., 3]]\n",
    "\n",
    "union.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e14a45-bd85-4e2b-9298-bc881f2f6d8e",
   "metadata": {},
   "source": [
    "# Exemplo: Titanic\n",
    "\n",
    "Trago aqui o exemplo [deste Notebook do Kaggle](https://www.kaggle.com/code/erkanhatipoglu/introduction-to-sklearn-pipelines-with-titanic), em que o autor define várias funções para lidar com os diferentes tipos de dados do *dataset* Titanic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ddfe1bf-7210-49de-ad72-8e6e74c6b936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import BinaryEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import FeatureUnion, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82046bff-4d98-4d9c-8726-29a2dbeb77c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar dataset Titanic - contém variáveis de diversos tipos\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url, index_col='PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c5a2d4e0-5868-4f09-93d5-232a644179ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funções úteis\n",
    "\n",
    "def get_titles(df):\n",
    "    '''Obter as entradas do campo Name (títulos como Mr, Mrs...)'''\n",
    "    titles=set()\n",
    "    for name in df:\n",
    "        if name.find('.'):\n",
    "            title = name.split('.')[0].split()[-1]\n",
    "            titles.add(title)\n",
    "    return titles\n",
    "\n",
    "\n",
    "def get_family_name(df):\n",
    "    '''Obter os nomes de família do campo Name'''\n",
    "    family_names=set()\n",
    "    for name in df:\n",
    "        if name.find(','):\n",
    "            family_name = name.split(',')[0].split()[-1]\n",
    "            family_names.add(family_name)\n",
    "    return family_names\n",
    "\n",
    "def get_cabin_chars(df):\n",
    "    '''Obter os caracteres do campo Cabin'''\n",
    "    cabin_chars = set()\n",
    "    for word in df:\n",
    "        cabin_chars.add(str(word)[0]) \n",
    "    return cabin_chars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c4cbed7-b203-4d89-9e35-a12da7df0eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[\"Survived\"]\n",
    "df.drop([\"Survived\", \"Ticket\"], axis=1, inplace=True)\n",
    "X = df.copy()\n",
    "\n",
    "# Split para validação\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X,y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "86163c89-3dab-4a67-9749-6d07119697de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas com valores faltantes: ['Age', 'Cabin', 'Embarked']\n",
      "Colunas numéricas: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Colunas categóricas: ['Name', 'Sex', 'Cabin', 'Embarked']\n",
      "\n",
      "Titles: ['Miss', 'Mlle', 'Don', 'Dr', 'Rev', 'Capt', 'Mme', 'Mr', 'Master', 'Sir', 'Mrs', 'Col', 'Lady', 'Countess', 'Ms', 'Jonkheer', 'Major']\n",
      "\n",
      "Chars in Cabin column: ['G', 'F', 'E', 'C', 'A', 'D', 'B', 'n', 'T']\n",
      "\n",
      "Surnames of the passengers: ['Brewe', 'Thayer', 'Humblen', 'Lindell', 'Reuchlin', 'Emanuel', 'Tornquist', 'Reynaldo', 'Johanson', 'Laitinen', 'Nankoff', 'Harper', 'Meanwell', 'Impe', 'Lemberopolous', 'Artagaveytia', 'Cairns', 'Silven', 'Dennis', 'Pekoniemi', 'Backstrom', 'Strom', 'Lobb', 'Bradley', 'Gustafsson', 'Hocking', 'Mullens', 'Sjoblom', 'Abbott', 'Wiseman', 'Davis', 'Danoff', 'Cunningham', 'Arnold-Franchi', 'Greenberg', 'Banfield', 'Goldenberg', 'Weir', 'Moore', 'Quick', 'Salonen', 'Newsom', 'Hays', 'Andrew', 'Zimmerman', 'Lindqvist', 'Ponesell', 'Andersson', 'Wiklund', 'Heikkinen', 'Betros', 'Thorneycroft', 'Asplund', 'Gilinski', 'McCarthy', 'Sharp', 'Lulic', 'Clifford', 'Mack', 'Dantcheff', 'Barton', 'Slayter', 'Olsvigen', 'Wright', 'Cavendish', 'Madigan', 'Gavey', 'Fleming', 'Jonsson', 'Horgan', 'Ling', 'Gaskell', 'Francatelli', 'Abbing', 'Johnson', 'Ilett', 'McMahon', 'Hood', 'Lester', 'Stead', 'Leonard', 'Bourke', 'Billiard', 'Bonnell', 'Chapman', 'Crease', 'Petranec', 'Minahan', 'Lindahl', 'Potter', 'Herman', 'Bing', 'Cribb', 'Parrish', 'Christy', 'McCormack', 'Coleff', 'Rosblom', 'Ohman', 'Futrelle', 'Dick', 'McGough', 'Shellard', 'Cumings', 'Corn', 'Tobin', 'Duane', 'Millet', 'Jensen', \"O'Brien\", 'Daniel', 'Eitemiller', 'Mockler', 'Spedden', 'Connaghton', 'Lahtinen', 'Peter', 'Davison', 'Sutton', 'Icard', 'Kenyon', 'Leitch', 'Saad', 'Markun', \"O'Dwyer\", 'Gilnagh', 'Louch', 'Beavan', 'Johannesen-Bratthammer', 'Stranden', 'Montvila', 'Gillespie', 'Richard', 'Windelov', 'Eustis', 'Douglas', 'Alexander', 'Aks', 'Zabour', 'Paulner', 'Klasen', 'Taylor', 'Melkebeke', 'Pavlovic', 'Sedgwick', 'Vestrom', 'Carrau', 'Mellinger', 'Kiernan', 'Bateman', 'Burke', 'Slabenoff', 'Steen', 'Najib', 'Smith', 'Karlsson', 'Odahl', 'West', 'Alhomaki', 'Kvillner', 'Cherry', 'Dimic', 'Giles', 'Cook', 'Simmons', 'Meyer', 'Devaney', 'Lemore', 'Gordon', 'Pettersson', 'Perkin', 'Moubarek', 'Beckwith', 'Hippach', 'Burns', 'Kallio', 'Sunderland', 'Nysten', 'Seward', 'Mionoff', 'Ahlin', 'Hunt', 'Moran', 'Karaic', 'Stankovic', 'Patchett', 'Cacic', 'Graham', 'Cor', 'Otter', 'Christmann', 'Sobey', 'Bowen', 'Mudd', 'Turcin', 'Cruyssen', 'Norman', 'Stahelin-Maeglin', 'Novel', 'Walker', 'Lefebre', 'Parkes', 'Young', 'Nakid', 'Jarvis', 'Plotcharsky', 'Behr', 'Astor', 'Aubart', 'Buss', 'Knight', 'Gheorgheff', 'Hogeboom', 'Scanlan', 'Moen', 'Toomey', 'Boulos', 'Harder', 'Rekic', 'Lahoud', 'Doharr', 'Bryhl', 'Asim', 'Hassan', 'Jonkoff', 'Porter', 'Willey', 'Yousseff', 'Barkworth', 'Beesley', 'Maenpaa', 'Wheadon', 'Chronopoulos', 'Goodwin', 'Todoroff', 'Faunthorpe', 'Lewy', 'Maioni', 'Barbara', 'Velde', 'Hakkarainen', 'Butler', 'Leyson', 'Dodge', 'Somerton', 'Rood', 'Kelly', 'McCoy', 'Holm', 'Maisner', 'Pasic', 'Kilgannon', 'Vovk', 'Mannion', 'Widegren', 'Turpin', 'Jenkin', 'Staneff', 'Shutes', 'Murphy', 'Natsch', 'Messemaeker', 'Culumovic', 'Sawyer', 'Gale', 'Wick', 'Wells', 'Gallagher', 'Hawksford', 'Reeves', 'Slocovski', 'Jansson', 'Hale', 'Dorking', 'Johansson', 'Henry', 'Birkeland', 'Bissette', 'Smart', 'Rogers', 'Sadlier', 'Sinkkonen', 'Butt', 'Ford', 'Givard', 'Svensson', 'Walle', 'Woolner', 'Molson', 'Peters', 'Planke', 'Farrell', 'Angle', 'Webber', 'Hirvonen', 'Ali', 'Markoff', 'Nasser', 'Celotti', 'Rice', 'Shawah', 'Frauenthal', 'Palsson', 'Leeni', 'Albimona', 'Bowerman', 'Lundahl', 'Sirayanian', 'Holverson', 'Ostby', 'Caldwell', 'Smiljanic', 'Mellors', 'Razi', 'Abelson', 'Homer', 'Newell', 'Baclini', 'Thomas', 'Beane', 'Pernot', 'Carbines', 'Mangan', 'Anderson', 'Denkoff', 'Ekstrom', 'Ridsdale', 'Risien', 'Rommetvedt', 'Frolicher', 'Pain', 'Waelens', 'Ayoub', 'Stone', 'Kink', 'Sage', 'Murdlin', 'Garside', 'Carlo', 'Rintamaki', 'Keefe', 'Silverthorne', 'Petterson', 'Gee', 'Mamee', 'Tikkanen', 'Green', 'Flynn', 'Giglio', 'Keane', 'Stoytcheff', 'Sagesser', 'Bazzani', 'Persson', 'Ryan', 'Glynn', 'Jacobsohn', 'Kent', 'Laleff', 'Olsson', 'Nilsson', 'Lievens', 'Balkic', 'Baxter', 'McEvoy', 'Gill', 'Harknett', 'Hosono', 'Funk', \"O'Leary\", 'Mayne', 'Hart', 'Ross', 'Toufik', 'Panula', 'Davies', 'Gronnestad', 'Ball', 'Andreasson', 'Chambers', 'Davidson', 'Foreman', 'Frost', 'Jerwan', 'Brown', 'Hansen', 'Madsen', 'Myhrman', 'Pinsky', 'Morley', 'Swift', 'Roebling', 'Goldsmith', 'Fortune', 'Jermyn', 'Wilhelms', 'Berriman', 'Hickman', 'Connolly', 'Chaffee', 'Coutts', 'Hendekovic', 'Elsbury', 'Saundercock', 'Perreault', 'Endres', 'Cardeza', 'White', 'Osen', 'Manent', 'Thorne', 'Nysveen', 'Ward', 'Sheerlinck', 'Nenkoff', 'Landergren', 'Braund', 'Yasbeck', 'Bostandyeff', 'Strandberg', 'Harrington', 'Watson', 'Milling', 'Bengtsson', \"O'Connell\", 'Sutehall', 'Carlsson', 'Dahl', 'Clarke', 'Dakic', 'Sirota', 'Moss', 'Laroche', 'Theobald', 'Carr', 'Matthews', 'Lurette', 'Haas', 'Sundman', 'hoef', 'Emir', 'Isham', 'Weisz', 'Yrois', 'Johnston', 'Mulder', 'Partner', 'Appleton', 'Rush', 'Larsson', 'Andrews', 'Nicholson', 'Williams', 'Allison', 'Pears', 'Collyer', 'Marvin', 'Coelho', 'Heininen', 'Samaan', 'Hampe', 'Honkanen', 'Baumann', 'Romaine', 'Calderhead', 'Warren', 'Sandstrom', 'Morrow', 'Caram', 'Eklund', 'Bystrom', 'Ringhini', 'Danbom', 'Simonius-Blumer', 'Brocklebank', 'Stewart', 'Bjornstrom-Steffansson', 'Longley', 'Naidenoff', 'Masselmani', 'Lennon', 'Kraeff', 'Serepeca', 'Stanley', 'Lesurer', 'Peuchen', 'Moutal', 'Kassem', 'Lovell', 'Hedman', 'Hamalainen', 'Pickard', 'Drew', 'Robbins', \"O'Sullivan\", 'Augustsson', 'Sdycoff', 'Stephenson', 'Troutt', 'More', 'Adams', 'Hagland', 'Mineff', 'Nye', 'Saalfeld', 'McNamee', 'Byles', 'Salkjelsvik', 'Phillips', 'Touma', 'Petroff', 'Attalah', 'Nicola-Yarred', 'Youseff', 'Moraweck', 'Kimball', 'Navratil', 'Oreskovic', 'Farthing', 'Nosworthy', 'Robins', 'Blackwell', 'Rothschild', 'Becker', 'Ivanoff', 'Kink-Heilmann', 'Kantor', 'Nicholls', 'Leader', 'Parr', 'Long', 'Canavan', 'Connors', 'Calic', 'Allum', 'Richards', 'Cann', 'Adahl', 'Lang', 'Blank', 'Olsen', 'Nirva', 'Daly', 'Torber', 'Ilmakangas', 'Spencer', 'Collander', 'Goncalves', 'Hassab', 'Rugg', 'Rothes', 'Mitkoff', 'Watt', 'Kirkland', 'Sivic', 'Uruchurtu', 'Crosby', 'Dean', 'Dowdell', \"O'Connor\", 'Goldschmidt', 'Frolicher-Stehli', 'Marechal', 'Shorney', 'Dooley', 'Fynney', 'Turja', 'Fahlstrom', 'Elias', 'Fry', 'Trout', 'Niskanen', 'Bishop', 'Jussila', 'Klaber', 'Bailey', 'Barah', 'Chip', 'Badt', 'Cohen', 'Coleridge', 'Barber', 'Mitchell', 'Edvardsson', 'Hewlett', \"O'Driscoll\", 'Hanna', 'Leinonen', 'Pengelly', 'Castellana', 'Radeff', 'McGovern', 'Levy', 'Kalvik', 'Turkula', 'Karun', 'McGowan', 'Healy', 'McDermott', 'Meo', 'Reed', 'Meek', 'Coxon', 'Campbell', 'Shelley', 'Rouse', 'Skoog', 'Taussig', 'Doling', 'Tomlin', 'Hegarty', 'Lindblom', 'Drazenoic', 'Lehmann', 'Moor', 'Pelsmaeker', 'Sjostedt', 'Jardin', 'Carter', 'Cameron', 'Troupiansky', 'Hoyt', 'Robert', 'Ryerson', 'Yousif', 'McKane', 'Bidois', 'Bracken', 'Mernagh', 'Allen', 'Mallet', 'Colley', 'Hold', 'Harris', 'Sloper', 'Harrison', 'Silvey', 'LeRoy', 'Slemen', 'Fischer', 'Hodges', 'Williams-Lambert', 'Lam', 'Dahlberg', 'Soholt', 'Cleaver', 'Lines', 'Jalsevac', 'Andersen-Jensen', 'Chibnall', 'Renouf', 'Guggenheim', 'Compton', 'Moussa', 'Greenfield', 'Foo', 'Garfirth', 'Charters', 'Harmer', 'Fox', 'Madill', 'Downton', 'Widener', 'Sivola', 'Osman', 'Berglund', 'Peduzzi']\n"
     ]
    }
   ],
   "source": [
    "# Identificar colunas com valores faltantes\n",
    "missing_values = [col for col in X_train.columns if X_train[col].isnull().sum()]\n",
    "print(\"Colunas com valores faltantes: {}\".format(missing_values))\n",
    "\n",
    "# Identificar colunas numéricas e categóricas pelo dtype\n",
    "numerical_columns = [col for col in X.columns if X[col].dtype in ['int64',\n",
    "                                                                  'float64']]\n",
    "print(\"Colunas numéricas: {}\".format(numerical_columns))\n",
    "\n",
    "categorical_columns = [col for col in X.columns if X[col].dtype==\"object\"]\n",
    "print(\"Colunas categóricas: {}\".format(categorical_columns))\n",
    "\n",
    "# Extrair títulos da coluna Name\n",
    "titles = list(get_titles(X[\"Name\"]))\n",
    "print(\"\\nTitles: {}\".format(titles))\n",
    "\n",
    "# Extrair caracteres da coluna Cabin\n",
    "chars = list(get_cabin_chars(X[\"Cabin\"]))\n",
    "print(\"\\nChars in Cabin column: {}\".format(chars))\n",
    "\n",
    "# Extrair sobrenomes da coluna Name\n",
    "surname = list(get_family_name(X[\"Name\"]))\n",
    "print(\"\\nSurnames of the passengers: {}\".format(surname))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0c98751f-7b0c-4aa9-a67c-020182c95b8b",
   "metadata": {},
   "source": [
    "Aqui ele criou três transformadores personalizados para as colunas Name, Age e Cabin. Não vou entrar em detalhes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73e741a6-0158-49fc-9254-0cb49bb3ee86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom transformer classes\n",
    "class NameColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    a general class for transforming Name, SibSp and Parch columns of Titanic dataset\n",
    "    for using in the machine learning pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "        \"\"\"\n",
    "        # Will be used for fitting data\n",
    "        self.titles_set = set()\n",
    "        self.surname_set = set()\n",
    "        # Titles captured from train data\n",
    "        self.normal_titles_list = [\"Mr\", \"Mrs\", \"Mme\", \"Miss\", \"Mlle\", \"Ms\", \"Master\", \"Dona\"]\n",
    "        self.titles_dict = {\"Mr\": ['Mr', 'Major', 'Jonkheer', 'Capt', 'Col', 'Don', 'Sir',\n",
    "                                   'Rev'],\n",
    "                            \"Mrs\": ['Mrs', 'Mme', 'Lady','Countess', 'Dona'],\n",
    "                            \"Miss\": ['Miss', 'Mlle', 'Ms'],\n",
    "                            \"Master\": ['Master'],\n",
    "                            \"Dr\": ['Dr']}\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to fit the step and to learn by examples\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: self: the class object - an instance of the transformer - Transformer\n",
    "        \"\"\"\n",
    "        '''Fits the titles, family and rank from Names Column'''\n",
    "        \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()\n",
    "        # Create Titles column\n",
    "        if \"Title\" in X_temp.columns:\n",
    "            X_temp.drop(\"Title\", axis=1, inplace=True)\n",
    "        else:\n",
    "            pd.DataFrame.insert(X_temp, len(X_temp.columns),\"Title\",\"\",False)  \n",
    "            \n",
    "        # Get the index values\n",
    "        index_values=X_temp.index.values.astype(int)\n",
    "        \n",
    "        # Set state (Add to: {titles_set, surname_set} attributes) of the object\n",
    "        for i in index_values:\n",
    "            \n",
    "            # Get the name for the ith index\n",
    "            name = X_temp.loc[i,'Name']\n",
    "            # Get the number of followers for the ith index\n",
    "            number_of_followers = X_temp.loc [i, 'SibSp'] + X_temp.loc [i, 'Parch']\n",
    "            \n",
    "            # Split the title from name\n",
    "            if name.find('.'):\n",
    "                title = name.split('.')[0].split()[-1]\n",
    "                if title in self.titles_dict.keys():\n",
    "                    X_temp.loc[i, 'Title'] = title\n",
    "                else:\n",
    "                    X_temp.loc[i, 'Title'] = np.NaN\n",
    "                # Add title to titles_set to use in transform method\n",
    "                self.titles_set.add(title)\n",
    "            \n",
    "            # Split the surname from name\n",
    "            if name.find(','):\n",
    "                surname = name.split(',')[0].split()[-1]\n",
    "                # Add surname to surname_set to use in transform method\n",
    "                if number_of_followers > 0:\n",
    "                    self.surname_set.add(surname)\n",
    "                    X_temp.loc[i,\"Family\"]=surname\n",
    "                \n",
    "        # Title Encoding\n",
    "        \n",
    "        # Drop missing Title rows (Hi rank columns that are mapped to titles_dict keys)\n",
    "        # so that no 'Title_' columns will appear in transform \n",
    "        X_temp.dropna(axis = \"index\", subset=['Title'], inplace=True)\n",
    "        \n",
    "        # Apply one-hot encoding to the Title column.\n",
    "        self.OH_encoder = OneHotEncoder(handle_unknown = 'ignore', sparse_output = False)\n",
    "        # Get column names to use in transform.\n",
    "        self.OH_encoder = self.OH_encoder.fit(X_temp[['Title']])\n",
    "        self.title_columns = self.OH_encoder.get_feature_names_out(['Title'])\n",
    "\n",
    "        # Family Encoding\n",
    "        \n",
    "        # Drop missing Family rows\n",
    "        # so that no 'Family_' columns will appear in transform \n",
    "        X_temp.dropna(axis = \"index\", subset=['Family'], inplace=True)\n",
    "        \n",
    "        # Apply binary encoding to the Family column.\n",
    "        self.binary_encoder = BinaryEncoder(cols =['Family'])\n",
    "        self.binary_encoder = self.binary_encoder.fit(X_temp[['Family']])\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to transform according to what happend in the fit method\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        '''Transforms the titles and family from Names Column'''\n",
    "        \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()\n",
    "        \n",
    "        # Create Titles column    \n",
    "        pd.DataFrame.insert(X_temp, len(X_temp.columns),\"Title\",\"\",False)    \n",
    "        # Create Family column\n",
    "        pd.DataFrame.insert(X_temp, len(X_temp.columns),\"Family\",\"\",False)          \n",
    "        # Create Rank column\n",
    "        pd.DataFrame.insert(X_temp, len(X_temp.columns),\"Rank\",\"\",False)\n",
    "        # Create Followers column\n",
    "        pd.DataFrame.insert(X_temp, len(X_temp.columns),\"Followers\",\"\",False)\n",
    "        \n",
    "        # Get the index values\n",
    "        index_values=X_temp.index.values.astype(int)\n",
    "        \n",
    "        for i in index_values:\n",
    "            # Get the name for the ith index\n",
    "            name = X_temp.loc[i,'Name']\n",
    "            # Get the number of followers for the ith index\n",
    "            number_of_followers = X_temp.loc [i, 'SibSp'] + X_temp.loc [i, 'Parch']\n",
    "            X_temp.loc[i, 'Followers'] = number_of_followers\n",
    "            \n",
    "            # Split the title from name\n",
    "            if name.find('.'):\n",
    "                title = name.split('.')[0].split()[-1]\n",
    "                if title in self.titles_set:\n",
    "                    for key in self.titles_dict:\n",
    "                        # Insert title\n",
    "                        if title in self.titles_dict[key]:\n",
    "                            X_temp.loc[i, 'Title'] = key \n",
    "                        \n",
    "                        # Insert rank\n",
    "                        if title in self.normal_titles_list:\n",
    "                            X_temp.loc[i, 'Rank'] = \"Normal\"\n",
    "                        else:\n",
    "                            X_temp.loc[i, 'Rank'] = \"High\"\n",
    "                else:\n",
    "                    X_temp.loc[i, 'Title'] = \"Other\"\n",
    "                    X_temp.loc[i, 'Rank'] = \"Normal\"\n",
    "                    \n",
    "                    \n",
    "            # Split the surname from name\n",
    "            if name.find(','):\n",
    "                surname = name.split(',')[0].split()[-1]\n",
    "                if surname in self.surname_set and number_of_followers > 0:\n",
    "                    X_temp.loc[i, 'Family'] = surname                 \n",
    "                else:\n",
    "                    X_temp.loc[i, 'Family'] = \"NA\"                    \n",
    "        \n",
    "        # Encoding Title\n",
    "        encoded = self.OH_encoder.transform(X_temp[['Title']])\n",
    "        # convert arrays to a dataframe \n",
    "        encoded = pd.DataFrame(encoded) \n",
    "        # One-hot encoding removed index; put it back\n",
    "        encoded.index = X_temp.index\n",
    "        # Insert column names\n",
    "        encoded.columns = self.title_columns\n",
    "        encoded = encoded.astype('int64')\n",
    "        # concating dataframes  \n",
    "        X_temp = pd.concat([X_temp, encoded], axis = 1)\n",
    "        \n",
    "        # Encoding Family\n",
    "        bin_encoded = self.binary_encoder.transform(X_temp[['Family']])\n",
    "        # convert arrays to a dataframe \n",
    "        bin_encoded = pd.DataFrame(bin_encoded) \n",
    "        # One-hot encoding removed index; put it back\n",
    "        bin_encoded.index = X_temp.index\n",
    "        bin_encoded = bin_encoded.astype('int64')\n",
    "        # concating dataframes  \n",
    "        X_temp = pd.concat([X_temp, bin_encoded], axis = 1)\n",
    "        # We do not need Family any more\n",
    "        X_temp.drop(\"Family\", axis = 1, inplace=True) \n",
    "        \n",
    "        # Encoding Rank\n",
    "        X_temp['Rank'] = X_temp['Rank'].apply(lambda x: 1 if x =='Normal' else (0 if x =='High' else None))\n",
    "        # We do not need Name any more\n",
    "        X_temp.drop(\"Name\", axis = 1, inplace=True)\n",
    "\n",
    "        return X_temp\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        perform fit and transform over the data\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X, y)\n",
    "\n",
    "    \n",
    "# Custom transformer classes\n",
    "class AgeColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    a general class for transforming age column of Titanic dataset for using in the machine learning pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "        \"\"\"\n",
    "        # Will be used for fitting data\n",
    "        self.titles_set = set()\n",
    "        self.titles_dict = {}\n",
    "\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to fit the step and to learn by examples\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: self: the class object - an instance of the transformer - Transformer\n",
    "        \"\"\"\n",
    "        '''Fits the titles, family and rank from Names Column'''\n",
    " \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()\n",
    "    \n",
    "        # Get the index values\n",
    "        index_values = X_temp.index.values.astype(int)\n",
    "        \n",
    "        # Get all the titles from dataset\n",
    "        for i in index_values:\n",
    "            title = X_temp.loc [i, 'Title']\n",
    "            self.titles_set.add(title)\n",
    "        \n",
    "        # Calculate mean for all titles\n",
    "        for title in self.titles_set:\n",
    "            mean = self.calculate_mean_age(title, X_temp)\n",
    "            self.titles_dict[title] = mean\n",
    "            #print(\"Avarage age for title '{}' is {}\".format(title, mean))\n",
    "       \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to transform according to what happend in the fit method\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        '''Transforms the titles and family from Names Column'''\n",
    "            \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()        \n",
    "        \n",
    "        # Get the index values\n",
    "        index_values = X_temp.index.values.astype(int)\n",
    "        \n",
    "        # If a passangers age is Nan replace it with the avarage value\n",
    "        # of that title class. e.g. if that passanger is master use the\n",
    "        # mean value calculated for the masters.\n",
    "        for i in index_values:\n",
    "            age = X_temp.at[i, 'Age'].astype(float)\n",
    "            if np.isnan(age):\n",
    "                title = X_temp.loc [i, 'Title']\n",
    "                X_temp.loc[i,'Age'] =  round(self.titles_dict.get(title),2)\n",
    "\n",
    "        # We do not need Title any more\n",
    "        X_temp.drop(\"Title\", axis = 1, inplace=True)\n",
    "        \n",
    "        return X_temp\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        perform fit and transform over the data\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        self = self.fit(X, y)\n",
    "        \n",
    "        return self.transform(X, y)\n",
    "                   \n",
    "    def calculate_mean_age(self, title, X):\n",
    "        \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()  \n",
    "        \n",
    "        # title_X = X_temp[[title in x for x in X_temp['Title']]][X_temp[\"Age\"].notnull()]\n",
    "        title_X = X_temp[[title in x for x in X_temp['Title']] & X_temp[\"Age\"].notnull()]\n",
    "        return title_X[\"Age\"].mean()\n",
    "\n",
    "\n",
    "# Custom transformer classes\n",
    "class CabinColumnTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    a general class for transforming cabin column of Titanic dataset for using in the machine \n",
    "    learning pipeline\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        constructor\n",
    "        \"\"\"\n",
    "        # Will be used for fitting data\n",
    "        self.cabin_set = set()\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to fit the step and to learn by examples\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: self: the class object - an instance of the transformer - Transformer\n",
    "        \"\"\"\n",
    "        '''Fits the titles, family and rank from Names Column'''\n",
    "         \n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()\n",
    "        \n",
    "        # Imputation on X_temp_imputed\n",
    "        imputer = SimpleImputer(strategy='constant', fill_value=\"NaN\")\n",
    "        X_temp_imputed = pd.DataFrame(imputer.fit_transform(X_temp[['Cabin']]))\n",
    "        # Imputation removed column names; put them back\n",
    "        X_temp_imputed.columns = X_temp[['Cabin']].columns\n",
    "        X_temp_imputed.index = X_temp[['Cabin']].index\n",
    "    \n",
    "        # Get the index values\n",
    "        index_values = X_temp.index.values.astype(int)\n",
    "        \n",
    "        # For each cabin\n",
    "        for i in index_values:\n",
    "            cabin = X_temp_imputed.loc[i, 'Cabin']\n",
    "            X_temp_imputed.loc[i, 'Cabin'] = cabin[0]\n",
    "            self.cabin_set.add(cabin[0])\n",
    "        \n",
    "        # Cabin Encoding\n",
    "        \n",
    "        # Apply one-hot encoding to the Cabin column.\n",
    "        self.OH_encoder = OneHotEncoder(handle_unknown = 'ignore', sparse_output = False)\n",
    "        # Get column names to use in transform.\n",
    "        self.OH_encoder = self.OH_encoder.fit(X_temp_imputed[['Cabin']])\n",
    "        self.cabin_columns = self.OH_encoder.get_feature_names_out(['Cabin'])\n",
    "      \n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        an abstract method that is used to transform according to what happend in the fit method\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        '''Transforms the titles and family from Names Column'''\n",
    "\n",
    "        # Make a copy to avoid changing original data\n",
    "        X_temp = X.copy()        \n",
    "        \n",
    "        # Get the index values\n",
    "        index_values = X_temp.index.values.astype(int)\n",
    "        \n",
    "        # Imputation on X_imputed\n",
    "        imputer = SimpleImputer(strategy='constant', fill_value=\"NaN\")\n",
    "        X_imputed = pd.DataFrame(imputer.fit_transform(X_temp[['Cabin']]))\n",
    "        # Imputation removed column names; put them back\n",
    "        X_imputed.columns = X_temp[['Cabin']].columns\n",
    "        X_imputed.index = X_temp[['Cabin']].index\n",
    "        \n",
    "        for i in index_values:\n",
    "            cabin = X_imputed.loc[i, 'Cabin']\n",
    "            if cabin[0] in self.cabin_set:\n",
    "                X_imputed.loc [i, 'Cabin'] = cabin[0]\n",
    "            else:\n",
    "                X_imputed.loc [i, 'Cabin'] = \"N\"\n",
    "        X_temp.drop(\"Cabin\",axis = 1, inplace = True)\n",
    "\n",
    "        # concating dataframes  \n",
    "        X_temp = pd.concat([X_temp, X_imputed], axis = 1)\n",
    "               \n",
    "        # Encoding Cabin\n",
    "        encoded = self.OH_encoder.transform(X_imputed[['Cabin']])\n",
    "        # convert arrays to a dataframe \n",
    "        encoded = pd.DataFrame(encoded) \n",
    "        # One-hot encoding removed index; put it back\n",
    "        encoded.index = X_imputed.index\n",
    "        # Insert column names\n",
    "        encoded.columns = self.cabin_columns\n",
    "        encoded = encoded.astype('int64')\n",
    "        # concating dataframes  \n",
    "        X_temp = pd.concat([X_temp, encoded], axis = 1)\n",
    "\n",
    "        X_temp.drop(\"Cabin\",axis = 1, inplace = True)\n",
    "        \n",
    "        return X_temp\n",
    "\n",
    "    def fit_transform(self, X, y=None, **kwargs):\n",
    "        \"\"\"\n",
    "        perform fit and transform over the data\n",
    "        :param X: features - Dataframe\n",
    "        :param y: target vector - Series\n",
    "        :param kwargs: free parameters - dictionary\n",
    "        :return: X: the transformed data - Dataframe\n",
    "        \"\"\"\n",
    "        self = self.fit(X, y)\n",
    "        return self.transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06714587-ee1c-405d-a607-fee6b362d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir os transformadores customizados\n",
    "name_transformer = NameColumnTransformer()\n",
    "age_transformer = AgeColumnTransformer()\n",
    "cabin_transformer = CabinColumnTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c30ba978-c56a-47bb-9414-836f3c2d7629",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir as colunas que serão processadas pelo ColumnTransformer, para as quais\n",
    "# não serão usadas os transformadores personalizados\n",
    "numerical_cols = ['Pclass', 'Fare']\n",
    "categorical_cols = ['Sex', 'Embarked']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "658644a6-e3c1-43ca-897e-d7e3c1c936ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para os dados numéricos\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "\n",
    "# Pipeline para os dados categóricos\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown = 'ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Juntar os pipelines para dados numéricos e categóricos usando ColumnTransformer\n",
    "# remainder='passthrough' indica que as colunas não processadas são mantidas\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numerical', numerical_transformer, numerical_cols),\n",
    "        ('categorical', categorical_transformer, categorical_cols)\n",
    "    ], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e4960b71-4906-48c0-ba77-1414321dd10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redução de dimensionalidade \n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# Além disso, vamos manter algumas das colunas originais usando SelectKBest\n",
    "selection = SelectKBest(k=12)\n",
    "\n",
    "# Aplicar ambas as transformações em paralelo usando FeatureUnion\n",
    "feature_union = FeatureUnion([('pca', pca), ('select', selection)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "317aed78-ba31-4678-8c85-bbb9d6b056b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Definir pipeline de preprocessamento\n",
    "preprocessor = Pipeline(steps=[('name', name_transformer),\n",
    "                              ('age', age_transformer),\n",
    "                              ('cabin', cabin_transformer),\n",
    "                              ('column', column_transformer),\n",
    "                              ('union', feature_union)])\n",
    "\n",
    "# Preprocessar conjunto de validação\n",
    "X_valid_transf = preprocessor.fit(X_train, y_train).transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5531649-a0d6-4109-9b78-2d7a06c42035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restam 14 variáveis\n"
     ]
    }
   ],
   "source": [
    "# Display the number of remaining columns after transformation \n",
    "print(\"Restam\", X_valid_transf.shape[1], \"variáveis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a07a95bf-92a4-42ca-8abe-207c43858282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir modelo\n",
    "my_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5e58363-86d4-47a8-ab84-ae6c23fc48d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7892376681614349"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criar e executar o Pipeline\n",
    "# Juntamos as etapas de preprocessamento com o modelo\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                              ('model', my_model)\n",
    "                             ])\n",
    "\n",
    "# O conjunto de treinamento é preprocessado e é feito o fit do modelo\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# As predições são obtidas para o conjunto de validação\n",
    "preds = my_pipeline.predict(X_valid)\n",
    "\n",
    "# Finalmente, determinamos a acurácia do modelo\n",
    "score = accuracy_score(y_valid, preds)\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b719e0f-ae61-424f-9842-7d1b3fd26b57",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "https://inria.github.io/scikit-learn-mooc/python_scripts/03_categorical_pipeline_column_transformer.html\n",
    "\n",
    "https://www.kaggle.com/code/erkanhatipoglu/introduction-to-sklearn-pipelines-with-titanic\n",
    "\n",
    "https://medium.com/@ayush-thakur02/wait-what-are-pipelines-in-python-628f4b5021fd\n",
    "\n",
    "https://machinelearningmastery.com/modeling-pipeline-optimization-with-scikit-learn/\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33bcdc-be9a-4956-8a31-f74b15b62fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
